---
title: "Performance Assessment with Python"
author: David Meyer
date: 12.3.2021
output:
  pdf_document: 
    toc: yes
    number_sections: yes
  html_notebook: default
---

# Data preparation

Use iris data:

```{python}
from sklearn import datasets
iris = datasets.load_iris()
X = iris.data
y = iris.target
```

## Train/Test-Split

```{python}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = \
    train_test_split(X, y,
                     test_size = 0.20,
                     stratify = y,
                     random_state = 4711)
```

## Cross-Validation

Create k-NN clasifier:

```{python}
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)
```

Use stratified Cross-Validation for Error Estimation:

```{python}
from sklearn.model_selection import cross_val_score
import numpy as np

scores = cross_val_score(estimator = knn,
                         X = X_train,
                         y = y_train,
                         groups = y_train,
                         cv = 10)

print('mean score: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))
```

# Parameter tuning

## Simple Cross-Validation

```{python}
from sklearn.model_selection import GridSearchCV

gs = GridSearchCV(estimator = knn,
                  param_grid = {'n_neighbors' : list(range(1,10))},
                  scoring = 'accuracy',
                  cv = 10,
                  refit = True)
best_model = gs.fit(X_train, y_train).best_estimator_

print('Best k : %d' % best_model.get_params()['n_neighbors'])
```

Assess performance on test set:

```{python}
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

pred = best_model.predict(X_test)

print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred, target_names = iris.target_names))
```

Nicer confusion matrix:

```{python}
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(best_model,X_test,y_test)
plt.show()
```

## Nested Cross-Validation

```{python}
gs = GridSearchCV(estimator = knn,
                  param_grid = {'n_neighbors' : list(range(1,10))},
                  scoring = 'accuracy',
                  cv = 2)
                  
scores = cross_val_score(gs, iris.data, iris.target,
                         groups = iris.target,
                         scoring = 'accuracy', cv = 5)

print('mean score: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))
```

# ROC-Curve

Create train/test split

```{python}
import pandas as pd
census = pd.read_csv("/home/meyer/kurse/ml/NaiveBayes/census.csv")[['income','age','hours.per.week']]
X_train, X_test, y_train, y_test = \
          train_test_split(census[['age','hours.per.week']], 
                           census['income'],
                           test_size = 0.20,
                           stratify = census['income'],
                           random_state = 4711)
```

Use NB-classifier for metric predictors (assuming gaussian distribution)

```{python}
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB().fit(X_train, y_train)
```

Draw ROC curve

```{python}
from sklearn.metrics import plot_roc_curve
plot_roc_curve(gnb, X_test, y_test)
plt.plot([0, 0, 1, 0], [0, 1, 1, 0], linestyle = ':', color = 'black')
plt.show()
```


